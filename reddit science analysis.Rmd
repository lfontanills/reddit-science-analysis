---
title: "Reddit Science Analysis"
author: "Laura Fontanills"
date: "2022-12-08"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

### Required packages

```{r load packages, include=FALSE}
library(readr) # create data frames
library(tidyverse) # data cleaning
library(lubridate) # wrangle dates
library(skimr) # skim dataset
library(ggplot2) # create visualization
library(urltools) # wrangle urls
```

### Data scraping

Use scraper.py to generate 3 .csv files, corresponding to the top 100 posts of the last month, year, and of all-time. Each of these contain 9 variables:
- `...1` ranks the post from 0-99 (highest score to lowest score)
- `id` is a unique string of letters and numbers that identify each post. Each post only has 1 id.
- `created_unix_utc` is the time the post was created as a unix number.
- `post_url` is the url for the website the post links to. This can be from an online news outlet, journal, etc.. Each post has a unique url.
- `post_title` is the title of the post.
- `flair` is a tag attached to each post by a moderator that places that post in a category. Categories are fields of science and include biology, physics, psychology, and news.
- `score` is the number of times a post was upvoted by a user (indicating that they found the post interesting and relevant to the subreddit).
- `num_comments` is the number of unique comments a post received. This does not include edits to comments.
- `upvote_ratio` is the ratio of upvotes (approval) to downvotes (disapproval) a post received. It is formatted as a decimal from 0 to 1.

```{r create dataframes, include=FALSE}
# create and view data frame with top 100 posts from the last month
top_month <- read_csv("Top-Posts-Month.csv")
View(top_month)

# create and view data frame with top 100 posts from the last year
top_year <- read_csv("Top-Posts-Year.csv")
View(top_year)

# create view data frame with top 100 posts from all time
top_all <- read_csv("Top-Posts-All.csv")
View(top_all)
```

### Data cleaning

Data frames are already tidy: one row per post, one column per variable, each post is unique

Before combining data frame - rename the column in each data frame 
```{r rename rank column}
# change column 1 name from ...1 to all_time_rank, year_rank, or month_rank
colnames(top_all)[1] <- "all_time_rank"
colnames(top_year)[1] <- "year_rank"
colnames(top_month)[1] <- "month_rank"
```


I am going to add 1 to the ranking columns so they go from 1-100
```{r change ranking}
# add 1 to all the rankings for clarity
top_all$all_time_rank = top_all$all_time_rank + 1
top_year$year_rank = top_year$year_rank + 1
top_month$month_rank = top_month$month_rank + 1
```

I made a new column with the unix timestamp converted to a datetime (UTC)

```{r create datetime}
# change created_unix_utc to a datetime
top_all$created_utc <- as_datetime(top_all$created_unix_utc)

top_year$created_utc <- as_datetime(top_year$created_unix_utc)

top_month$created_utc <- as_datetime(top_month$created_unix_utc)
```

I isolated the domain name from the url and created the column `domain`
```{r create domain column}
# make column with domain name only
top_all$domain <- domain(top_all$post_url)

top_year$domain <- domain(top_year$post_url)

top_month$domain <- domain(top_month$post_url)
```


Next I'll combine the three data frames into one
```{r combine dataframes}
# combine data frames
top_post_temp <- full_join(top_all, top_year)
top_posts <- full_join(top_post_temp, top_month)
```

### Exploratory data analysis

```{r skim dataframe}
skim(top_posts)
```
1. Completeness: There are no missing or incorrect values in the data sets. There are 13 variables and 298 rows (some posts appeared in multiple time periods, most appeared in just one). The top posts covered 20 science topics (flair) and came from 145 domains. None of the numerical variables show normal distribution. 

2. Distribution: the histograms from skim(top_all) indicate that these measures don't follow a normal distribution (The same is true when assessing each timeframe independently). A Shapiro-Wilk normality test confirms this. I am looking for relationships between the number of posts and topic (flair), so I won't go further with analyzing relationships between my numerical variables.

```{r shapiro test}
shapiro.test(top_all$score)
shapiro.test(top_all$num_comments)
shapiro.test(top_all$upvote_ratio)
```

3. Explore relationships between topic(flair) and number of posts. No clear relationship between flair and upvote ratio. Highest numbers by month, year, and all are Health, Psychology, and Social Sciences

```{r summarize flair by time period}
# Group by topic flair
by_flair_month <- top_month %>% 
  group_by(flair) %>% 
  summarize(count_id=n_distinct(id))

by_flair_year <- top_year %>% 
  group_by(flair) %>% 
  summarize(count_id=n_distinct(id))

by_flair_all <- top_all %>% 
  group_by(flair) %>% 
  summarize(count_id=n_distinct(id))

# graph number of posts by flair

ggplot(by_flair_month, aes(x=flair, y=count_id)) +
  geom_col()

ggplot(by_flair_year, aes(x=flair, y=count_id)) +
  geom_col()

ggplot(by_flair_all, aes(x=flair, y=count_id)) +
  geom_col()

```

4. Explore relationships between source (domain name) and number of posts

```{r summarize domain by time period}
# Group by domain name

by_domain_month <- top_month %>% 
  group_by(domain) %>% 
  summarize(count_id=n_distinct(id))

by_domain_year <- top_year %>% 
  group_by(domain) %>% 
  summarize(count_id=n_distinct(id))

by_domain_all <- top_all %>% 
  group_by(domain) %>% 
  summarize(count_id=n_distinct(id))

by_domain_month %>% 
  arrange(desc(count_id))

by_domain_year %>% 
  arrange(desc(count_id))

by_domain_all %>% 
  arrange(desc(count_id))
```

5. Conclusions

Health, Psychology, and Social Science most frequently make top posts by month, year, and all-time. Psypost and eureka altet most frequently make top posts by month and year, but not all time, perhaps indicating a recent uptick in the number of posts using these sources (past year). 

This analysis would be improved by a longitudinal study, monitoring top posts over a period of time to get more information about which posts make the top each month, and how those filter out by year and all time. 

6. Next steps

I am curious about the number of posts from the same sources, about the same topics. I will conduct a text analysis of post titles to see what words and ideas make up the top posts on r/science