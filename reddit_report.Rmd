---
title: "Analyzing post topics and titles on reddit.com/r/science"
author: "Laura Fontanills"
date: "`r format(Sys.time(), '%d %B %Y')`"
mail: "lfontanills@gmail.com"
linkedin: "lfontanills"
github: "lfontanills"
home: "lfontanills.github.io"
# !!! You need to provide a logo image here !!! Or just delete the field for no logo
# logo: "logo_gallery.png"
logo: "reddit_logo.png"
output:
  epuRate::epurate:
    toc: TRUE
    number_sections: FALSE
    code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages, include=FALSE}
library(tidyverse) # data processing and analysis
library(lubridate) # wrangle dates
library(skimr) # skim data frames
library(urltools) # wrangle urls
```

# Read this first

If you'd like to skip all the data cleaning steps, click on "Get the data" in the sidebar.

# About

I spend a lot of time on reddit, and a few months ago I noticed that one subreddit I frequent, [r/science](reddit.com/r/science), had more and more posts about pop-psychology getting tons of upvotes. Reddit is a social media site, and scientific journals are notoriously hard to access, so I expect a gap between the types of science content between them. Still, I decided to test my gut feeling that the subreddit's content was changing.

I want to see what kinds of posts made it to the top of r/science: the posts that have the most upvotes, and therefore the posts that the most people liked and engaged with. What topics interest the average r/science user the most? 

# Scraping Reddit with PRAW

I used a python script to scrape r/science top 100 posts over three time periods: the past month, the past year, and all-time. Within these time periods I obtained data for 9 different variables:
* `...1` ranks the post from 0-99 (0 being the highest rank).
* `id` is a unique string of letters and numbers that identify each post.
* `created_unix_utc` is the time the post was created (as a unix number).
* `post_url` is the url for the website the post links to. This can be from an online news outlet, journal, etc.. Each post has a unique url.
* `post_title` is the title of the post.
* `flair` is a tag attached to each post by a moderator that places that post in a category. It represents the post's topic.
* `score` is the number of times a post was upvoted (each user can upvote a post once).
* `num_comments` is the number of unique comments on a post.
* `upvote_ratio` is the ratio of upvotes (indivading user approval) to downvotes (indicating user disapproval).

The script won't run here; to run this code yourself, you'll need to follow the instructions [this guide](https://praw.readthedocs.io/en/stable/) and use your own credentials.

```{python scraper.py, eval=FALSE, include=FALSE}
# import packages
import praw
import pandas

# read-only instance
reddit_read_only = praw.Reddit(
    client_id="", #your info here
    client_secret="", #your info here
    user_agent="", #your info here
)

# extract subreddit information

subreddit = reddit_read_only.subreddit("science")

# display subreddit name

print("Display Name:", subreddit.display_name)

# display subreddit title
print("Title:", subreddit.title)

# display subreddit description
print("Description:", subreddit.description)

# get top posts this from time period
# all = all time
# year = past year
# month = past month
posts = subreddit.top("all")

posts_dict = { 
    "id": [],
    "created_unix_utc": [],
    "post_url": [],
    "post_title": [],
    "flair": [],
    "score": [],
    "num_comments": [],
    "upvote_ratio": []
}

for post in posts:
    posts_dict["id"].append(post.id)
    posts_dict["created_unix_utc"].append(post.created_utc)
    posts_dict["post_url"].append(post.url)
    posts_dict["post_title"].append(post.title)
    posts_dict["flair"].append(post.link_flair_text)
    posts_dict["score"].append(post.score)
    posts_dict["num_comments"].append(post.num_comments)
    posts_dict["upvote_ratio"].append(post.upvote_ratio)

# change this when scraping different time periods
top_posts_all= pandas.DataFrame(posts_dict)
top_posts_all

top_posts_all.to_csv("Top-Posts-All.csv")
# repeat for past year, past month
```


# Data cleaning

```{r read raw data frames}
# create data frame with top 100 posts from the last month
top_month <- read_csv("Top-Posts-Month.csv")

# create data frame with top 100 posts from the last year
top_year <- read_csv("Top-Posts-Year.csv")

# create data frame with top 100 posts from all time
top_all <- read_csv("Top-Posts-All.csv")
```

I confirm that all posts are unique by checking the number of distinct post IDs. TRUE indicates that all rows are unique.

```{r check all posts unique}
n_distinct(top_all$id) == nrow(top_all)
n_distinct(top_year$id) == nrow(top_year)
n_distinct(top_month$id) == nrow(top_month)
```

I change the name of the first column to represent post rank, and add 1 to all rankings so that posts are ranked from 1 to 100.

```{r edit column names - rank}

# change column 1 name from ...1 to rank
colnames(top_all)[1] <- "all_rank"
colnames(top_year)[1] <- "year_rank"
colnames(top_month)[1] <- "month_rank"

# add 1 to all the rankings for clarity
top_all$all_rank = top_all$all_rank + 1
top_year$year_rank = top_year$year_rank + 1
top_month$month_rank = top_month$month_rank + 1
```

I convert the created_unix field from a number to a datetime, and save this as `created_utc`. This shows the time each post was made in UTC.

```{r create unix_utc datetime}

top_all$created_utc <- as_datetime(top_all$created_unix_utc)
top_year$created_utc <- as_datetime(top_year$created_unix_utc)
top_month$created_utc <- as_datetime(top_month$created_unix_utc)
```

I isolate the domain name from each post url, and save this as post_url. This shows the source website of each post -- sources include news outlets, science magazines, journals, blogs, etc..

```{r create post_url chr}

top_all$domain <- domain(top_all$post_url)
top_year$domain <- domain(top_year$post_url)
top_month$domain <- domain(top_month$post_url)
```

A look at the data summary for top_all shows that the oldest post is from 2015, and the median post is from 2020. More recent posts are overrepresented, so the subreddit must be growing over time. The summary also confirms that posts are ranked from 1 to 100.

```{r}
summary(top_all)
summary(top_year)
summary(top_month)
```

Let's save the cleaned and transformed data to fresh data frames.

```{r}
all_clean <- top_all
year_clean <- top_year
month_clean <- top_month
```


# Get the data

I created individual data frames for the top 100 posts of all time, the last year, and the last month.

I also created data frames containing just the post titles for each time period.

I did not combine these data frames because they each represent a different timescale.
```{r}
# Whole dataset
top_all <- read.csv("~/Documents/Projects/reddit-science-analysis-2/top_all.csv")
top_year <- read.csv("~/Documents/Projects/reddit-science-analysis-2/top_year.csv")
top_month <- read.csv("~/Documents/Projects/reddit-science-analysis-2/top_month.csv")

# Post titles only
tidy_all <- read.csv("~/Documents/Projects/reddit-science-analysis-2/tidy_all.csv")
tidy_year <- read.csv("~/Documents/Projects/reddit-science-analysis-2/tidy_year.csv")
tidy_month <- read.csv("~/Documents/Projects/reddit-science-analysis-2/tidy_month.csv")

```

The top_all file has `r nrow(top_all)` lines and `r ncol(top_all)` columns. It is ready to be analyzed.

The top_year file has `r nrow(top_year)` lines and `r ncol(top_year)` columns. It is ready to be analyzed.

The top_month file has `r nrow(top_month)` lines and `r ncol(top_month)` columns. It is ready to be analyzed.

The tidy_all file contains `r nrow(tidy_all)` words. The tidy_year file contanils `r nrow(tidy_year)` words. The tidy_month file contanils `r nrow(tidy_month)` words.

# Analysis and Visualizations
***
Posts are ranked by their score (which is the same as the number of upvotes). Each post has "flair" which designates the topic. Each post has exactly 1 topic flair. I chose to use assigned flair for this analysis, rather than designating my own topics.

A quick look at the numerical values in my data sets showed that score, number of comments, and upvote ratio (the ratio of upvote to downvotes) scaled with post rank (see appendix). I decided to focus instead on the number of posts by topic. 

It is worth noting that there are a few posts with very low upvote ratios (less than 75%), even though they also have very high scores. This indicates high engagement of users with both positive and negative opinions about the post. Effectively all of these posts are about contentious or divisive issues, and many are US-centric. Broadly, these posts are about:
* Top_month: Marijuana, women's sexual desire
* Top_year: US politics, US gun violence, LGBTQ+, covid-19 vaccines, Gen-Z climate change beliefs, Bitcoin,
racism, Trump, sexism, refugees in the US, neoliberalism, abortion, religion
* Top_all: US comedy-news programs, Trump

```{r}
# find post with very low upvote ratio
# all time
top_all %>% 
  filter(upvote_ratio < .75 ) %>% 
  arrange(upvote_ratio) %>% 
  select(c(post_title, flair, upvote_ratio, score, domain))

# past year
top_year %>% 
  filter(upvote_ratio < .75 ) %>% 
  arrange(upvote_ratio) %>% 
  select(c(post_title, flair, upvote_ratio, score, domain))

# past month
top_month %>% 
  filter(upvote_ratio < .75 ) %>% 
  arrange(upvote_ratio) %>% 
  select(c(post_title, flair, upvote_ratio, score, domain))

```

## Finding 1: Relationship between topic and post score

Three topics dominate the top-post lists for all timeframes: Psychology, Health, and Social Science. Together, these make up 51% of the top posts of all time (59% top month, 56% top year). 

```{r}
# all-time
by_flair_all <- top_all %>% 
  group_by(flair) %>% 
  summarize(count_id=n_distinct(id)) %>% 
  arrange(desc(count_id)) %>% 
  ggplot(aes(x = count_id, y=reorder(flair, count_id), fill=flair)) +
  geom_col(show.legend=FALSE) +
  gghighlight(count_id > 10) +
  labs(
    title = "Top r/science posts by topic",
    subtitle = "Top 100 posts of all time",
    x = "Number of Posts",
    y = "Topic"
  ) +
  theme_minimal()
by_flair_all

# past year
by_flair_year <- top_year %>% 
  group_by(flair) %>% 
  summarize(count_id=n_distinct(id)) %>% 
  arrange(desc(count_id)) %>% 
  ggplot(aes(x = count_id, y=reorder(flair, count_id), fill=flair)) +
  geom_col(show.legend=FALSE) +
  scale_fill_brewer(palette = "BuGn") +
  gghighlight(count_id > 10) +
  labs(
    title = "Top r/science posts by topic",
    subtitle = "Top 100 posts last year (2022)",
    x = "Number of Posts",
    y = "Topic"
  ) +
  theme_minimal()
by_flair_year

# past month
by_flair_month <- top_month %>% 
  group_by(flair) %>% 
  summarize(count_id=n_distinct(id)) %>% 
  arrange(desc(count_id)) %>% 
  ggplot(aes(x = count_id, y=reorder(flair, count_id), fill=flair)) +
  geom_col(show.legend=FALSE) +
  gghighlight(count_id > 10) +
  scale_fill_brewer(palette = "BuPu", direction = -1) +
  labs(
    title = "Top r/science posts by topic",
    subtitle = "Top 100 posts last month (December 2022)",
    x = "Number of Posts",
    y = "Topic"
  ) +
  theme_minimal()
by_flair_month
```

## Finding 2: Relationship between sources and post score

The top posts link to 60+ source websites (identified by domain name, e.g. academictimes.com). For the top posts of all time, no single source has more than 5 posts linked to it. However, for the past year, 14 unique posts come from psypost.org. For the past month, 17 posts come from psypost.org. This indicates a recent increase in the popularity of posts from this website.

```{r}
# all-time
by_domain_all <- top_all %>% 
  group_by(domain) %>% 
  summarize(count_id=n_distinct(id)) %>% 
  arrange(desc(count_id)) %>% 
  head(10) %>% 
  ggplot(aes(x = count_id, y=reorder(domain, count_id), fill=domain)) +
  geom_col(show.legend=FALSE) +
  gghighlight(count_id > 10) +
  labs(
    title = "Top 10 sources for r/science",
    subtitle = "For the top 100 posts of all time",
    x = "Number of Posts",
    y = "Topic"
  ) +
  theme_minimal()
by_domain_all

# past year
by_domain_year <- top_year %>% 
  group_by(domain) %>% 
  summarize(count_id=n_distinct(id)) %>% 
  arrange(desc(count_id)) %>% 
  head(10) %>% 
  ggplot(aes(x = count_id, y=reorder(domain, count_id), fill=domain)) +
  geom_col(show.legend=FALSE) +
  scale_fill_brewer(palette = "Greens", direction = -1) +
  gghighlight(count_id > 10 ) +
  labs(
    title = "Top 10 sources for r/science",
    subtitle = "Top 100 posts last year (2022)",
    x = "Number of Posts",
    y = "Topic"
  ) +
  theme_minimal()
by_domain_year

# past month
by_domain_month <- top_month %>% 
  group_by(domain) %>% 
  summarize(count_id=n_distinct(id)) %>% 
  arrange(desc(count_id)) %>% 
  head(10) %>% 
  ggplot(aes(x = count_id, y=reorder(domain, count_id), fill=domain)) +
  geom_col(show.legend=FALSE) +
  gghighlight(count_id > 10) +
  scale_fill_brewer(palette = "PRGn") +
  labs(
    title = "Top 10 sources for r/science",
    subtitle = "Top 100 posts last month (December 2022)",
    x = "Number of Posts",
    y = "Topic"
  ) +
  theme_minimal()
by_domain_month
```

## Finding 3: Word frequency in post titles

To find the most common words in top post titles, I created dataframes with just post titles, then used unnest_tokens() to separate each word into its own column. I filtered out stopwords and created wordclouds to show the most frequent words in the titles of the top posts of all time. The word "people" appeared 12 times, "children" appeared 8 times, "sex" appeared 8 times, "life" appeared 7 times, and "U.S." appeared 6 times.
```{r}

all_words <- tidy_all %>% count(word, sort=TRUE)
wordcloud2(all_words, size = 1.6)
```



The past-year word list looks different from the all-time list, and represents more recent trends on the subreddit. The word "black" appeared 8 times, "woman" appeared 8 times, and "lung" appeared 7 times.
```{r}

year_words <- tidy_year %>% count(word, sort=TRUE)
wordcloud2(year_words, size = 1.6, color = (c("green","blue")))

```


## Finding 4: Comparing word frequency to another science source

The words in reddit top posts titles are very weakly correlated with the words from the homepages of a popular science source, [Frontiers](https://blog.frontiersin.org/). I chose Frontiers because  it is an open-source journal with a webpage that posts article summaries and science news, much like r/science does. There are some similarities between this wordcloud and the all-time wordcloud, but some of the more frequently-used words in the Reddit wordcloud are missing from the Frontiers wordcloud (e.g. "sex", "life", and "U.S.". Furthermore, no one word appears as often as the top words in Reddit titles: "DNA" appears 6 times, and "science" appears 4 times.

```{r warning=FALSE, include=FALSE}
tidy_frontiers <- read_csv("~/Documents/Projects/reddit-science-analysis-2/tidy_frontiers.csv", show_col_types = FALSE)

```
```{r}
# word cloud
frontiers_words <- tidy_frontiers %>% count(word, sort=TRUE)
wordcloud2(frontiers_words, size = 1.6, color=(c("red","purple")))
```

# Conclusions


Reddit is, first and foremost, a social media site. The most upvoted posts are those favored by the user base. Reddit's r/science skews heavily toward psychology, social science, and health articles. I expected that posts would more frequently link to science blogs and magazines (rather than peer-reviewed journals), but I was surprised by how overrepresented one site in particular -- psypost.com. was in the top posts of the past year and all time. These posts are highly upvoted and have high engagement. Based on titles, some words appear very frequently in the top posts. 
Personally, I would love to see more diversity in the top posts, in terms of both sources and topics, because if I wanted my feed to be a series of psypost articles...well, I'd just go straight to psypost. 

## Some extras
